{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and benchmarking gene representations using Granite\n",
    "The third generation of [Granite AI language models](https://www.ibm.com/granite) can deliver exceptional performance across a wide range of enterprise tasks, and Gene-Benchmarks is a package to benchmark pre-trained models on downstream gene-related tasks. In this notebook we will use the Granite models to create gene embeddings and then use the Gene-Benchmark package by doing do the following:\n",
    "1. Extract gene embeddings from the granite model\n",
    "2. Evaluate the quality of the embedding on a prediction task.\n",
    "3. Two special bonuses for the dedicated reader who goes through the entire notebook\n",
    "\n",
    "Together, this will give us a comprehensive picture of how well the Granite model can “understand” the properties of genes (more background can be found in our manuscript - [Does your model understand genes? A benchmark of gene properties for biological and text models\n",
    "](https://arxiv.org/abs/2412.04075)).   \n",
    "Let’s start by setting up the environment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "from gene_benchmark.descriptor import NCBIDescriptor\n",
    "from gene_benchmark.encoder import SentenceTransformerEncoder\n",
    "from gene_benchmark.tasks import EntitiesTask, load_task_definition\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a task in gene-benchmark\n",
    "\n",
    "The gene-benchmark package includes 293 gene-related tasks testing the ability to predict various properties. Each task is defined by a set of entities (gene symbols) and their corresponding properties (outcomes). For this notebook we use an example of a task called \"bivalent vs non-methylated\", which includes a set of genes and an indication of whether they are bivalent or non-methylated (see further details in this [manuscript](https://arxiv.org/pdf/2412.04075)).  \n",
    "\n",
    "Here’s a quick example of how to look at the definitions of the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>Outcomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOXA11</td>\n",
       "      <td>bivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAX6</td>\n",
       "      <td>bivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZIC2</td>\n",
       "      <td>bivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COASY</td>\n",
       "      <td>bivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAX2</td>\n",
       "      <td>bivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  Outcomes\n",
       "0  HOXA11  bivalent\n",
       "1    PAX6  bivalent\n",
       "2    ZIC2  bivalent\n",
       "3   COASY  bivalent\n",
       "4    PAX2  bivalent"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = load_task_definition(\"bivalent vs non-methylated\",tasks_folder=\"../tasks\")\n",
    "pd.concat([task.entities,task.outcomes],axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract gene embeddings from the granite model\n",
    "The question of gene embeddings from a text model is complex. We could potentially just give the model the name of the gene and extract the embeddings. However, in our experience this provides very poor performance since the name is usually some arbitrary abbreviation of the gene description (for example, the gene BRCA1 is shorthand for “Breast Cancer Type 1 Susceptibility Protein”).  \n",
    "\n",
    "We therefore opted to provide the text models with a more comprehensive description of the gene.The Gene-Benchmark package provides easy functions to extract the gene description from the [NCBI](https://www.ncbi.nlm.nih.gov/gene/), resulting in a data frame with the required descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene symbol HOXA11 full name homeobox A11 with the summary In vertebrates, the genes encoding the class of transcription factors called homeobox genes are found in clusters named A, B, C, and D on four separate chromosomes. Expression of these proteins is spatially and temporally regulated during embryonic development. This gene is part of the A cluster on chromosome 7 and encodes a DNA-binding transcription factor which may regulate gene expression, morphogenesis, and differentiation. This gene is involved in the regulation of uterine development and is required for female fertility. Mutations in this gene can cause radio-ulnar synostosis with amegakaryocytic thrombocytopenia. [provided by RefSeq, Jul 2008].\n"
     ]
    }
   ],
   "source": [
    "description_builder=NCBIDescriptor()\n",
    "descriptions = description_builder.describe(task.entities)\n",
    "print(descriptions.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package also provides a wrapper function that gives the gene description as input to the language model and then extract the embeddings.  \n",
    "Any text model that following the HuggingFace [SentenceTransformer](https://sbert.net/) API can be used, here we will use the [granite embedding model](https://huggingface.co/ibm-granite/granite-embedding-125m-english) that delivers high-performance sentence-transformer models optimized for retrieval, generating precise embeddings and is built on ethically sourced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:06<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "granite_model = \"ibm-granite/granite-embedding-125m-english\"\n",
    "granite_embedding = SentenceTransformerEncoder(granite_model)\n",
    "encodings = granite_embedding.encode(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate the quality of the embedding on a prediction task.\n",
    "Now that we have the embeddings, we can estimate their utility for the task. Gene-benchmark provide k-fold cross validation of the prediction task to evaluate the performance and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:03<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mean AUC: 0.91 sd: 0.06\n"
     ]
    }
   ],
   "source": [
    "task = EntitiesTask(\n",
    "    task=\"bivalent vs non-methylated\",\n",
    "    description_builder=NCBIDescriptor(),\n",
    "    encoder=SentenceTransformerEncoder(granite_model),\n",
    "    tasks_folder=\"../tasks\"\n",
    ")\n",
    "_ = task.run()\n",
    "print(f\" mean AUC: {task.summary()['mean_roc_auc']:.2f} sd: {task.summary()['sd_roc_auc']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: evaluating multiple encodings and multiple tasks\n",
    "We showed an example of how to create the embeddings for a specific task. Batch evaluation of multiple tasks and models it can be done using the `run_task.py` script, which outputs the performance into a CSV file.  \n",
    "This requires defining a YAML file for each model, defining the name of the model, the task list, etc. For example, the three YAML files in [this folder](./granite_files) allow running evaluations of 3 versions of granite on two tasks available in Gene-Benchmarks using the following command line:\n",
    "\n",
    "`python run_task.py -t \"Gene2Gene\" -t \"long vs short range TF\"  -m granite_files/granite8b.yaml -m granite_files/granite2b.yaml -m granite_files/graniteEmbed.yaml --output-file-name /performance/bin.csv`  \n",
    "\n",
    "## Bonus 2: evaluating multiple encodings and multiple tasks using lists\n",
    "\n",
    "If you want to run the models on a list of tasks you can use the task list file in [this folder](../scripts/task_configs) and run the script like this:  \n",
    "\n",
    "`python run_task.py -t   -m granite_files/granite8b.yaml -m granite_files/granite2b.yaml -m granite_files/graniteEmbed.yaml --output-file-name /performance/bin.csv -t scripts/task_configs/binary_tasks.yaml `  \n",
    "\n",
    "To run the script on multi-label or multi-class labels the user need to set the right scoring using the  scoring parameter `-s` see the script for additional details. \n",
    "We used the script to compare the performance on 293 tasks of three models - [Granite8B](https://huggingface.co/ibm-granite/granite-3.1-8b-base), [Granite2B](https://huggingface.co/ibm-granite/granite-3.1-2b-base) and [Granite embedding model](https://huggingface.co/ibm-granite/granite-embedding-125m-english).  \n",
    "\n",
    "  \n",
    "The overall results are presented as a heatmap. we can see that the embeddings model might be very small but it is comparable in performance to the larger general LLM models.  \n",
    "\n",
    "![overall](./granite_files/overall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a more finegrained understanding by looking at each task:  \n",
    "\n",
    "![performance](./granite_files/long.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For additional details see our manuscript [Does your model understand genes? A benchmark of gene properties for biological and text models\n",
    "](https://arxiv.org/abs/2412.04075)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
